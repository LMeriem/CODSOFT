# -*- coding: utf-8 -*-
"""SPAM SMS DETECTION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18BpvouCtpmKuaw-51QHtY2iNIgDoMRfE
"""

import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from sklearn.utils import class_weight
from wordcloud import WordCloud

# Load dataset with error handling
try:
    data = pd.read_csv('spam.csv', encoding='latin-1')
    data = data[['v1', 'v2']]  # Selecting relevant columns
    data.columns = ['label', 'message']  # Renaming columns
except FileNotFoundError:
    print("Error: The file was not found. Please check the file path.")
    exit()
except Exception as e:
    print(f"An error occurred: {e}")
    exit()

# EDA
plt.figure(figsize=(8, 6))
sns.countplot(x='label', data=data)
plt.title('Distribution of Spam and Ham Messages')
plt.xlabel('Label')
plt.ylabel('Count')
plt.show()

spam_messages = ' '.join(data[data['label'] == 'spam']['message'])
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(spam_messages)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud for Spam Messages')
plt.show()

# Preprocess data
data['message'] = data['message'].apply(lambda x: re.sub(r'[^a-zA-Z\s]', '', x.lower()))

# Split data
X_train, X_test, y_train, y_test = train_test_split(data['message'], data['label'], test_size=0.2, random_state=42)

# Feature extraction
tfidf = TfidfVectorizer()
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

# Convert labels to numerical format
y_train_numeric = np.where(y_train == 'spam', 1, 0)  # Convert 'spam' to 1 and 'ham' to 0
y_test_numeric = np.where(y_test == 'spam', 1, 0)  # Convert 'spam' to 1 and 'ham' to 0 for evaluation

# Handling imbalanced classes
class_weights = class_weight.compute_class_weight('balanced', classes=np.array([0, 1]), y=y_train_numeric)
class_weights_dict = {0: class_weights[0], 1: class_weights[1]}

# Define the parameter grid including class_weight
param_grid = {
    'C': [0.1, 1, 10],
    'penalty': ['l2'],
    'class_weight': [class_weights_dict, None]  # Use the computed class weights and also try without
}

# Initialize GridSearchCV without the class_weight in the model constructor
grid_search = GridSearchCV(LogisticRegression(solver='liblinear'), param_grid, cv=5, scoring='accuracy')

# Fit the model with GridSearchCV
grid_search.fit(X_train_tfidf, y_train_numeric)

# Get the best model
best_model = grid_search.best_estimator_
print("Best parameters for Logistic Regression:", grid_search.best_params_)

# Evaluation
y_pred = best_model.predict(X_test_tfidf)
print("Accuracy:", accuracy_score(y_test_numeric, y_pred))  # Use y_test_numeric for evaluation
print(classification_report(y_test_numeric, y_pred, target_names=['ham', 'spam'], zero_division=0))